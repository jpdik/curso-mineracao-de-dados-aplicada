{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import _thread\n",
    "import os\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "URL = \"https://www.letras.mus.br\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "letras = string.ascii_uppercase + '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(filename, df):\n",
    "    if os.path.exists(filename):\n",
    "        df.to_csv(filename, mode='a', index=False, header=False)\n",
    "    else:\n",
    "        df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gravar(dados, letra):\n",
    "    df = pd.DataFrame(np.array(dados), columns=['url', 'artist', 'title_music', 'original_lyrics', 'translated_lyrics'])\n",
    "    save(\"musicas-{}.csv\".format(letra), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_links_e_nomes(letra):\n",
    "    links = []\n",
    "    try:\n",
    "        print('Obtendo letra {}.'.format(letra))\n",
    "        http = urllib3.PoolManager()\n",
    "        url = URL+\"/letra/\"+letra+\"/artistas.html\"\n",
    "        html = http.request('GET', url).data\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        soup = soup.find('ul',{'class': \"cnt-list cnt-list--col3\"})\n",
    "        if soup:\n",
    "            for link in soup.find_all('a'):\n",
    "                if len(links) > 1:\n",
    "                    gravar(links, letra)\n",
    "                    links = []\n",
    "                url = URL+link.get('href')\n",
    "                html = http.request('GET', url).data\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                for a in soup.find_all('div',{'class':'artista-top'}):\n",
    "                    for link in a.find_all('a'):\n",
    "                        if 'contribuicoes' in link.get('href'):\n",
    "                            continue\n",
    "                        url = URL+link.get('href')\n",
    "                        musica = link.text\n",
    "                        artista = soup.find_all('h1')[-1].text\n",
    "                        html = http.request('GET', url+ \"traducao.html\").data\n",
    "                        \n",
    "                        soup = BeautifulSoup(html, 'html.parser')\n",
    "                        orig = soup.find('div',{'class': \"cnt-trad_l\"})\n",
    "                        trad = soup.find('div',{'class': \"cnt-trad_r\"})\n",
    "                        if orig != None and trad != None:\n",
    "                            links.append((url, artista, musica, orig.text, trad.text))\n",
    "                        else:\n",
    "                            orig = soup.find('div',{'class': \"cnt-letra\"})\n",
    "                            links.append((url, artista, musica, orig.text, None))\n",
    "        print('Thread da letra {} finalizada.'.format(letra))\n",
    "    except Exception:\n",
    "        import traceback\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtendo letra A.\n",
      "Obtendo letra G.\n",
      "Obtendo letra F.\n",
      "Obtendo letra N.\n",
      "Obtendo letra K.\n",
      "Obtendo letra T.\n",
      "Obtendo letra W.\n",
      "Obtendo letra Z.\n",
      "Obtendo letra D.\n",
      "Obtendo letra I.\n",
      "Obtendo letra B.\n",
      "Obtendo letra P.\n",
      "Obtendo letra U.\n",
      "Obtendo letra Y.\n",
      "Obtendo letra C.\n",
      "Obtendo letra J.\n",
      "Obtendo letra E.\n",
      "Obtendo letra L.\n",
      "Obtendo letra 1.\n",
      "Obtendo letra H.\n",
      "Obtendo letra V.Obtendo letra Q.\n",
      "Obtendo letra X.\n",
      "Obtendo letra S.\n",
      "Obtendo letra M.\n",
      "\n",
      "Obtendo letra R.\n",
      "Obtendo letra O.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for letra in letras:\n",
    "        _thread.start_new_thread(obter_links_e_nomes, (letra,) )\n",
    "except Exception as e:\n",
    "    print (\"Error: unable to start thread: \"+ str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "http = urllib3.PoolManager()\n",
    "url = URL+\"/os-qdelicias/ela-me-envolve/\" + \"traducao.html\"\n",
    "html = http.request('GET', url).data\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "orig = soup.find('div',{'class': \"cnt-trad_l\"})\n",
    "trad = soup.find('div',{'class': \"cnt-trad_r\"})\n",
    "if orig != None and trad != None:\n",
    "    print(orig.text)\n",
    "    print(trad.text)\n",
    "else:\n",
    "    orig = soup.find('div',{'class': \"cnt-letra\"})\n",
    "    print(orig.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('h1')[-1].text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
