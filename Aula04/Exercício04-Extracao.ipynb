{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "# Remoção de acentos\n",
    "from unicodedata import normalize\n",
    "import _thread\n",
    "import time\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 200\n",
    "PARTS = 4\n",
    "\n",
    "dados = []\n",
    "\n",
    "BASE_URL = \"http://www.barbacena.ifsudestemg.edu.br\"\n",
    "\n",
    "def get_sites(num_thread, offset):\n",
    "    try:\n",
    "        global MAX, PARTS, BASE_URL, dados\n",
    "\n",
    "        for i in range(int(offset), int(offset+MAX/PARTS)):\n",
    "            html = requests.get(BASE_URL+'/nodequeue/3?page='+str(i)).text\n",
    "\n",
    "            sub_urls = re.findall(r'<a href=\"(/destaques.+)\"', html)\n",
    "            for sub_url in sub_urls:\n",
    "                html = requests.get(BASE_URL+sub_url).text\n",
    "                link = BASE_URL+sub_url\n",
    "                data = re.findall(r'<div class=\"submitted\">Postado em (.+),', html)[0]\n",
    "                title = re.findall(r'<h1 class=\"title\">(.+)</h1>', html)[0]\n",
    "                desc = \"\"\n",
    "                for match in re.finditer('<p class=\"rtejustify\">(.*?)</p>', html, re.S):\n",
    "                    desc += match.group(1)\n",
    "                dados.append((data, title, link, desc))\n",
    "    except Exception:\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "try:\n",
    "    for i in range(PARTS):\n",
    "        _thread.start_new_thread(get_sites, (i, MAX/PARTS*i) )\n",
    "except Exception as e:\n",
    "    print (\"Error: unable to start thread: \"+ str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4504"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dados, columns=['data', 'titulo', 'link', 'descricao'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('noticias_if.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
